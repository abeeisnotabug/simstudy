---
title: "Simulating study data"
author: "Keith S. Goldfeld"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Simulating study data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<STYLE TYPE="text/css">
<!--
  td{
    font-family: Arial; 
    font-size: 8pt;
    height: 2px;
    padding:0px;
    cellpadding="0";
    cellspacing="0";
    text-align: center;
  }
  th {
    font-family: Arial; 
    font-size: 9pt;
    height: 20px;
    font-weight: bold;
    text-align: center;
  }
  table { 
    border-spacing: 0px;
    border-collapse: collapse;
  }
--->
</STYLE>

```{r, echo = FALSE, message = FALSE}
library(simstudy)
library(ggplot2)
library(gridExtra)

set.seed(3333)

ggtheme <- function(panelback = "white") {
  
  ggplot2::theme(
    panel.background = element_rect(fill = panelback),
    panel.grid = element_blank(),
    axis.ticks =  element_line(colour = "black"),
    panel.margin =unit(0.25, "lines"),  # requires package grid
    panel.border = element_rect(fill = NA, colour="gray90"), 
    plot.title = element_text(size = 8,vjust=.5,hjust=0),
    axis.text = element_text(size=8),
    axis.title = element_text(size = 8)
  )  
  
}

splotfunc <- function(dt, ptitle) {

  dtplot <- dt[,.N,keyby=.(male, over65, rxGrp)][, .(rxGrp, grp = male * 2 + over65 * 1, N)]
  ggplot(dtplot, aes(factor(grp), N)) +
    geom_bar(aes(fill = factor(rxGrp)), alpha=.8, position = "dodge", stat="identity") +
    scale_fill_manual(values = c("#971f5d", "#5d971f", "#1f5d97")) +
    ggtitle(ptitle) +
    theme(legend.position = "none") +
    ggtheme() +
    xlab("Strata") +
    ylim(0,80)
}

aplotfunc <- function(dt, ptitle) {

  dtplot <- dt[,.N,keyby=.(rxGrp)]
  ggplot(dtplot, aes(factor(rxGrp), N)) +
    geom_bar(aes(fill = factor(rxGrp)), alpha=.8, position="dodge", stat="identity", width=.5) +
    scale_fill_manual(values = c("#971f5d", "#5d971f", "#1f5d97")) +
    ggtitle(ptitle) +
    theme(legend.position = "none") +
    ggtheme() +
    xlab("Treatment group") +
    ylim(0,150)
}
```

Simulation using `simstudy` has two primary steps. First, the user **defines** the data elements of a data set. Second, the user **generates** the data, using the definitions in the first step. Additional functionality exists to simulate observed or randomized **treatment assignment/exposures**, to create **multi-level/hierarchical** data, to create datasets with **correlated variables** based on a specified covariance structure, to **merge** datasets, and to create data sets with **missing** data.

## Defining the data

A data set *definition* is created as a data.table (a high powered data.frame) by repeated calls to function `defData`, or with a single call to `defRead` to read in an external set of data set definitions. Here, we illustrate building the definitions internally:

```{r, tidy = TRUE}
def <- defData(varname = "nr", dist = "Nonrandom", formula=7, id = "idnum")
def <- defData(def,varname="x1",dist="Uniform",formula="10, 20")
def <- defData(def,varname="y1",formula="nr + x1 * 2",variance=8)
def <- defData(def,varname="y2",dist="Poisson",formula="nr - 0.2 * x1",link="Log")
def <- defData(def,varname="xCat",formula = "0.3, 0.2, 0.5",dist="Categorical")
def <- defData(def, varname = "a1", dist = "Binary" , formula="-3 + xCat", link="Logit")
```
<br>

Following initialization and the subsequent five calls to `add.defs`, these are the contents of the data.table `def`:

```{r,  echo=FALSE}
knitr::kable(def)
```

\newline
<br>

The call to `initDefs` creates a new data.table with a single row. `initDefs` takes a single string argument representing the name of the `id` field; the default is 'id'.\

A row is added to the table `def` each time the function `defData` is called. Each of these calls is the definition of a new field in the data set that will be generated. In this example, the first data field is named 'nr', defined as a constant with a value to be 7. In each call to `defData` the user defines a variable name, a distribution (the default is 'Normal'), a mean formula (if applicable), a variance parameter (if applicable), and a link function for the mean (defaults to 'identity').\

The possible distributions include **normal**, **Poisson**, **zero-truncated Poisson**, **binary**, **uniform**, **categorical**, and **deterministic/non-random**. For all of these distributions, key parameters defining the distribution are entered in the `formula`, `variance`, and `link` fields. 

In the case of the **normal** distribution, the formula specifies the mean. The formula can be a scalar value (number) or a string that represents a function of previously defined variables in the data set definition (or, as we will see later, in a previously generated data set). In the example, the mean of `y1`, a normally distributed value, is declared as a linear function of `nr` and `x1`. The `variance` field is defined only for normal random variables, and can only be defined as a scalar value.\

In the case of the **Poisson**, **zero-truncated Poisson**, and **binary** distributions, the formula also specifies the mean. The variance is not a valid parameter in these cases, but the `link` field is. The default link is 'identity' but a 'Log' link is available for the Poisson distributions and a "Logit" link is available for the binary outcomes. In this example, `y2` is defined as Poisson random variable with a mean that is function of `nr` and `x1` on the log scale. For binary variables, which take a value of 0 or 1, the formula represents probability (with the 'identity' link) or log odds (with the 'Logit' link) of the variable having a value of 1. In the example, `a1` has been defined as a binary random variable with a log odds that is a function of `xCat`.\

Variables defined with a **uniform**, **categorical**, or **deterministic/non-random** distribution are specified using the formula only. The `variance` and `link` fields are not used in these cases.\

For a uniformly distributed variable, The formula is a string with the format "a, b", where *a* and *b* are scalars (i.e. not functions of other defined variables). The uniform distribution typically has two parameters - the minimum and the maximum. In this case, *a* represents the minimum and *b* represents the maximum.\

For a cateogrical variable with $k$ categories, the formula is a string of  probabilities that sum to 1: "$p_1$, $p_2$, ..., $p_k$". $p_1$ is the probability of the random variable falling category 1, $p_2$ is the probablity of category 2, etc. The probabilities cannot be specified as functions of other variables previously defined. In the example, `xCat` has three possibilities with probabilites 0.3, 0.2, and 0.5, respectively.\

Non-random variables are defined by the formula. Since these variables are deterministic, variance is not relevant. They can be functions of previously defined variables or a scalar, as we see in the sample for variable defined as `nr`.

## Generating the data

After the data set definitions have been created, a new data set with $n$ observations can be created with a call to function **`genData`**. In this example, 1,000 observations are generated using the data set defitions in **`def`**, and then stored in the object **`dt`**:\

```{r, tidy = TRUE}
dt <- genData(def,1000)
dt
```
<br>

New data can be added to an existing data set with a call to function **`addColumns`**. A new data definition is provided along with the name of the existing data set:\

```{r, tidy = TRUE}
addef <- defData(varname = "zExtra", dist = "Normal", formula = '3 + y1', 
                 variance = 2, id="idnum")

dt <- addColumns(addef, dt)
dt
```

## Generating the treatment/exposure

Treatment assignment can be accomplished through the original data generation process, using `defData` and `genData`. However, the functions `trtAssign` and `trtObserve` provide more options to generate treatment assignment.

Treatment assignment can simulate how treatment is made in a randomized study. Assignment to treatment groups can be (close to) balanced (as would occur in a block randomized trial); this balancing can be done without or without strata. Alternatively, the assignment can be left to chance without blocking; in this case, balance across treatment groups is not guaranteed, particularly with small sample sizes.

First, create the data definition:
```{r, tidy = TRUE}
def <- defData(varname = "male", dist = "Binary", formula = .5 , id="cid")
def <- defData(def, varname = "over65", dist = "Binary", formula = "-1.7 + .8*male", link="Logit")
def <- defData(def, varname = "z", dist = "Normal", formula = 10, variance = 2)

dtstudy <- genData(def, 330)
```

*Balanced treatment assignment, stratified by gender and age category*
```{r, tidy = TRUE}
study1 <- trtAssign(dtstudy , n=3, allocEqual = TRUE, strata = c("male","over65"), grpName = "rxGrp")

study1
```
*Balanced treatment assignment (without stratification)*
```{r, tidy = TRUE}
study2 <- trtAssign(dtstudy , n=3, allocEqual = TRUE, grpName = "rxGrp")
```
*Random (unbalanced) treatment assignment*
```{r, tidy = TRUE}
study3 <- trtAssign(dtstudy , n=3, allocEqual = FALSE, grpName = "rxGrp")
```
*Comparison of three treatment assignment mechanisms*
```{r, tidy = TRUE, echo = FALSE, fig.width = 4, fig.height = 6}
p1 <- splotfunc(study1, "Balanced within strata")
p1a <- aplotfunc(study1, "")

p2 <- splotfunc(study2, "Balanced without strata")
p2a <- aplotfunc(study2, "")

p3 <- splotfunc(study3, "Random allocation")
p3a <- aplotfunc(study3, "")

grid.arrange(p1, p1a, p2, p2a, p3, p3a, ncol=2)
```
<br>

If exposure or treatment is observed (rather than randomly assigned), use `trtObserved` to generate groups. There may be any number of possible exposure or treatment groups.

```{r, tidy = TRUE}
formula1 <- c("-2 + 2*male + .25*over65", "-1 - 1*male - .25*over65")
dtExp <- trtObserve(dtstudy, formulas = formula1, logit.link = TRUE, grpName = "exposure")

# plot something here
dtExp[, table(exposure), keyby=.(male, over65)]
```

## Longitudinal data

To simulate longitudinal data, we start with a 'cross-sectional' data set and convert it to time-dependendent data set. The original cross-sectional data set may or may not include time-dependent data in the columns. In the next example, we measure outcome `Y` once before and twice after intervention `T` in a randomized trial:\

```{r, tidy = TRUE}
tdef <- defData(varname = "T", dist="Binary", formula = 0.5)
tdef <- defData(tdef, varname = "Y0", dist = "Normal", formula = 10, variance = 1)
tdef <- defData(tdef, varname = "Y1", dist = "Normal", formula = "Y0 + 5 + 5 * T", variance = 1)
tdef <- defData(tdef, varname = "Y2", dist = "Normal", formula = "Y0 + 10 + 5 * T", variance = 1)

dtTrial <- genData(tdef, 500)
dtTrial
```
<br>
The data in longitudinal form is created with a call to **`addPeriods`**. If the cross-sectional data includes time dependent data, then the number of periods `nPeriods` must be the same as the number of time dependent columns. If a variable is not declared as one of the `timevars`, it will be repeated each time period. In this example, the treatment indicator `T` is not specified as a time dependent variable. (Note: if there are two time-dependent variables, it is best to create two data sets and merge them. This will be shown later in the vignette).\

```{r, tidy = TRUE}
dtTime <- addPeriods(dtTrial, nPeriods = 3, idvars = "id", timevars = c("Y0", "Y1", "Y2"), timevarName = "Y")
dtTime
```
<br>
This is what the longitudinal data look like:\

```{r, tidy = TRUE, echo = FALSE, fig.width = 6, fig.height = 3}

avg <- dtTime[,.(Y=mean(Y)), keyby = .(T, period)]

ggplot(data = dtTime, aes(x = factor(period), y = Y)) +
  geom_point(aes(color=factor(T)), size = 1) +
#  geom_smooth(aes(group=T, color = factor(T)), se = FALSE, method = "lm") +
  geom_line(data=avg, aes(x = factor(period), y = Y, group = T, color= factor(T)), size=1, lty = 1) +
  xlab("Period") +
  scale_color_manual(values=c("#769e39","#61399e"), 
                     labels = c("Ctrl", "Trt")) +
  theme(legend.title=element_blank())
```

## Clustered data

## Missing data

## Other topics

* Merge data
* Correlated data
* Treatment/exposure assignment
