---
title: "Simulating study data"
author: "Keith S. Goldfeld"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Simulating study data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<STYLE TYPE="text/css">
<!--
  td{
    font-family: Arial; 
    font-size: 8pt;
    height: 2px;
    padding:0px;
    cellpadding="0";
    cellspacing="0";
    text-align: center;
  }
  th {
    font-family: Arial; 
    font-size: 9pt;
    height: 20px;
    font-weight: bold;
    text-align: center;
  }
  table { 
    border-spacing: 0px;
    border-collapse: collapse;
  }
--->
</STYLE>

```{r, echo = FALSE, message = FALSE}
library(simstudy)
library(ggplot2)
library(grid)
library(gridExtra)

set.seed(3333)

plotcolors <- c("#B84226", "#1B8445", "#1C5974")

cbbPalette <- c("#EA846C", "#EAAF6C", "#487C93", 
                "#4EA872", "#811900", "#814400", 
                "#043A51", "#00260F")

ggtheme <- function(panelback = "white") {
  
  ggplot2::theme(
    panel.background = element_rect(fill = panelback),
    panel.grid = element_blank(),
    axis.ticks =  element_line(colour = "black"),
    panel.margin =unit(0.25, "lines"),  # requires package grid
    panel.border = element_rect(fill = NA, colour="gray90"), 
    plot.title = element_text(size = 8,vjust=.5,hjust=0),
    axis.text = element_text(size=8),
    axis.title = element_text(size = 8)
  )  
  
}

splotfunc <- function(dt, ptitle) {

  dtplot <- dt[,.N,keyby=.(male, over65, rxGrp)][, .(rxGrp, grp = male * 2 + over65 * 1, N)]
  ggplot(dtplot, aes(factor(grp), N)) +
    geom_bar(aes(fill = factor(rxGrp)), alpha=.8, position = "dodge", stat="identity") +
    scale_fill_manual(values = plotcolors) +
    ggtitle(ptitle) +
    theme(legend.position = "none") +
    ggtheme() +
    xlab("Strata") +
    ylim(0,80)
}

aplotfunc <- function(dt, ptitle) {

  dtplot <- dt[,.N,keyby=.(rxGrp)]
  ggplot(dtplot, aes(factor(rxGrp), N)) +
    geom_bar(aes(fill = factor(rxGrp)), alpha=.8, position="dodge", stat="identity", width=.5) +
    scale_fill_manual(values = plotcolors) +
    ggtitle(ptitle) +
    theme(legend.position = "none") +
    ggtheme() +
    xlab("Treatment group") +
    ylim(0,150)
}

ggmissing <- function(dtPlot,varSelect=NULL,varLevel=NULL, idvar = "id",
                      periodvar = "period", missvar,
                      pcolor="#738e75", title = NULL) {

  dtP <- copy(dtPlot)

  if (! is.null(varSelect)) dtP <- dtP[eval(parse(text=varSelect)) == varLevel]

  xp <- ggplot(data=dtP, aes(y = factor(eval(parse(text=idvar))),
                             x = eval(parse(text=periodvar)))) +
    geom_tile(aes(fill=factor(eval(parse(text=missvar)))),
                  color="white") +
    ggtheme()+
    theme(axis.text=element_blank(),
          axis.ticks=element_blank(),
          axis.title=element_blank(),
          legend.position="none",
          plot.title=element_text(size=8)
    ) +
    scale_fill_manual(values=c("grey80",pcolor))

  if (is.null(title)) {
    return(xp)
  } else {
    return(xp + ggtitle(title))
  }
}

```

Simulation using `simstudy` has two primary steps. First, the user **defines** the data elements of a data set. Second, the user **generates** the data, using the definitions in the first step. Additional functionality exists to simulate observed or randomized **treatment assignment/exposures**, to create **multi-level/hierarchical** data, to create datasets with **correlated variables** based on a specified covariance structure, to **merge** datasets, and to create data sets with **missing** data.

## Defining the data

A data set *definition* is created as a data.table (a high powered data.frame) by repeated calls to function `defData`, or with a single call to `defRead` to read in an external set of data set definitions. Here, we illustrate building the definitions internally:

```{r, tidy = TRUE}
def <- defData(varname = "nr", dist = "Nonrandom", formula=7, id = "idnum")
def <- defData(def,varname="x1",dist="Uniform",formula="10, 20")
def <- defData(def,varname="y1",formula="nr + x1 * 2",variance=8)
def <- defData(def,varname="y2",dist="Poisson",formula="nr - 0.2 * x1",link="Log")
def <- defData(def,varname="xCat",formula = "0.3, 0.2, 0.5",dist="Categorical")
def <- defData(def, varname = "a1", dist = "Binary" , formula="-3 + xCat", link="Logit")
```

Following initialization and the subsequent five calls to `add.defs`, these are the contents of the data.table `def`:

```{r,  echo=FALSE}
knitr::kable(def)
```

The call to `initDefs` creates a new data.table with a single row. `initDefs` takes a single string argument representing the name of the `id` field; the default is 'id'.\

A row is added to the table `def` each time the function `defData` is called. Each of these calls is the definition of a new field in the data set that will be generated. In this example, the first data field is named 'nr', defined as a constant with a value to be 7. In each call to `defData` the user defines a variable name, a distribution (the default is 'Normal'), a mean formula (if applicable), a variance parameter (if applicable), and a link function for the mean (defaults to 'identity').\

The possible distributions include **normal**, **Poisson**, **zero-truncated Poisson**, **binary**, **uniform**, **categorical**, and **deterministic/non-random**. For all of these distributions, key parameters defining the distribution are entered in the `formula`, `variance`, and `link` fields. 

In the case of the **normal** distribution, the formula specifies the mean. The formula can be a scalar value (number) or a string that represents a function of previously defined variables in the data set definition (or, as we will see later, in a previously generated data set). In the example, the mean of `y1`, a normally distributed value, is declared as a linear function of `nr` and `x1`. The `variance` field is defined only for normal random variables, and can only be defined as a scalar value.\

In the case of the **Poisson**, **zero-truncated Poisson**, and **binary** distributions, the formula also specifies the mean. The variance is not a valid parameter in these cases, but the `link` field is. The default link is 'identity' but a 'Log' link is available for the Poisson distributions and a "Logit" link is available for the binary outcomes. In this example, `y2` is defined as Poisson random variable with a mean that is function of `nr` and `x1` on the log scale. For binary variables, which take a value of 0 or 1, the formula represents probability (with the 'identity' link) or log odds (with the 'Logit' link) of the variable having a value of 1. In the example, `a1` has been defined as a binary random variable with a log odds that is a function of `xCat`.\

Variables defined with a **uniform**, **categorical**, or **deterministic/non-random** distribution are specified using the formula only. The `variance` and `link` fields are not used in these cases.\

For a uniformly distributed variable, The formula is a string with the format "a, b", where *a* and *b* are scalars (i.e. not functions of other defined variables). The uniform distribution typically has two parameters - the minimum and the maximum. In this case, *a* represents the minimum and *b* represents the maximum.\

For a cateogrical variable with $k$ categories, the formula is a string of  probabilities that sum to 1: "$p_1$, $p_2$, ..., $p_k$". $p_1$ is the probability of the random variable falling category 1, $p_2$ is the probablity of category 2, etc. The probabilities cannot be specified as functions of other variables previously defined. In the example, `xCat` has three possibilities with probabilites 0.3, 0.2, and 0.5, respectively.\

Non-random variables are defined by the formula. Since these variables are deterministic, variance is not relevant. They can be functions of previously defined variables or a scalar, as we see in the sample for variable defined as `nr`.

## Generating the data

After the data set definitions have been created, a new data set with $n$ observations can be created with a call to function **`genData`**. In this example, 1,000 observations are generated using the data set defitions in **`def`**, and then stored in the object **`dt`**:

```{r, tidy = TRUE}
dt <- genData(def,1000)
dt
```

New data can be added to an existing data set with a call to function **`addColumns`**. A new data definition is provided along with the name of the existing data set:

```{r, tidy = TRUE}
addef <- defData(varname = "zExtra", dist = "Normal", formula = '3 + y1', 
                 variance = 2, id="idnum")

dt <- addColumns(addef, dt)
dt
```

## Generating the treatment/exposure

Treatment assignment can be accomplished through the original data generation process, using `defData` and `genData`. However, the functions `trtAssign` and `trtObserve` provide more options to generate treatment assignment.

### Assigned treatment

Treatment assignment can simulate how treatment is made in a randomized study. Assignment to treatment groups can be (close to) balanced (as would occur in a block randomized trial); this balancing can be done without or without strata. Alternatively, the assignment can be left to chance without blocking; in this case, balance across treatment groups is not guaranteed, particularly with small sample sizes.

First, create the data definition:

```{r, tidy = TRUE}
def <- defData(varname = "male", dist = "Binary", formula = .5 , id="cid")
def <- defData(def, varname = "over65", dist = "Binary", formula = "-1.7 + .8*male", link="Logit")
def <- defData(def, varname = "z", dist = "Normal", formula = 10, variance = 2)

dtstudy <- genData(def, 330)
```

*Balanced treatment assignment, stratified by gender and age category*
```{r, tidy = TRUE}
study1 <- trtAssign(dtstudy , n=3, balanced = TRUE, strata = c("male","over65"), grpName = "rxGrp")

study1
```

*Balanced treatment assignment (without stratification)*
```{r, tidy = TRUE}
study2 <- trtAssign(dtstudy , n=3, balanced = TRUE, grpName = "rxGrp")
```

*Random (unbalanced) treatment assignment*
```{r, tidy = TRUE}
study3 <- trtAssign(dtstudy , n=3, balanced = FALSE, grpName = "rxGrp")
```

*Comparison of three treatment assignment mechanisms*
```{r, tidy = TRUE, echo = FALSE, fig.width = 4, fig.height = 6}
p1 <- splotfunc(study1, "Balanced within strata")
p1a <- aplotfunc(study1, "")

p2 <- splotfunc(study2, "Balanced without strata")
p2a <- aplotfunc(study2, "")

p3 <- splotfunc(study3, "Random allocation")
p3a <- aplotfunc(study3, "")

grid.arrange(p1, p1a, p2, p2a, p3, p3a, ncol=2)
```

### Observed treatment

If exposure or treatment is observed (rather than randomly assigned), use `trtObserved` to generate groups. There may be any number of possible exposure or treatment groups, and the probability of exposure to a specific level can depend on covariates already in the data set. In this case, there are three exposure groups that vary by gender and age:

```{r, tidy = TRUE}
formula1 <- c("-2 + 2*male - .5*over65", "-1 + 2*male + .5*over65")
dtExp <- trtObserve(dtstudy, formulas = formula1, logit.link = TRUE, grpName = "exposure")
```

Here are the exposure distributions by gender and age:

```{r, tidy = TRUE, echo = FALSE, fig.width = 6.5, fig.height = 2.5}
dtplot1 <- dtExp[,.N,keyby=.(male,exposure)]
p1 <- ggplot(data = dtplot1, aes(x=factor(male), y=N)) +
  geom_bar(aes(fill=factor(exposure)), alpha = .8, stat="identity", position = "dodge") +
  ggtheme() +
  theme(axis.title.x = element_blank()) +
  theme(legend.title = element_text(size = 8)) +
  ylim(0, 150) +
  scale_fill_manual(values = plotcolors, name = "Exposure") +
  scale_x_discrete(breaks = c(0, 1), labels = c("Female", "Male")) +
  ylab("Number exposed")+
  ggtitle("Gender")

dtplot2 <- dtExp[,.N,keyby=.(over65,exposure)]
p2 <- ggplot(data = dtplot2, aes(x=factor(over65), y=N)) +
  geom_bar(aes(fill=factor(exposure)), alpha = .8, stat="identity", position = "dodge") +
  ggtheme() +
  theme(axis.title.x = element_blank()) +
  theme(legend.title = element_text(size = 8)) +
  ylim(0, 150) +
  scale_fill_manual(values = plotcolors, name = "Exposure") +
  scale_x_discrete(breaks = c(0, 1), labels = c("65 or younger", "Over 65")) +
  ylab("Number exposed") +
  ggtitle("Age")

grid.arrange(p1,p2,nrow=1)

```

Here is a second case of three exposures where the exposure is indepdendent of any covariates. Note that specifying the formula as `c(.35, .45)` is the same as specifying it is `c(.35, .45, .20)`. Also, when referring to probabilities, the identity link is used:

```{r, tidy = TRUE}
formula2 <- c(.35, .45)

dtExp2 <- trtObserve(dtstudy, formulas = formula2, logit.link = FALSE, grpName = "exposure")
```

```{r, tidy = TRUE, echo = FALSE, fig.width = 6.5, fig.height = 2.5}
dtplot1a <- dtExp2[,.N,keyby=.(male,exposure)]
p1a <- ggplot(data = dtplot1a, aes(x=factor(male), y=N)) +
  geom_bar(aes(fill=factor(exposure)), alpha = .8, stat="identity", position = "dodge") +
  ggtheme() +
  theme(axis.title.x = element_blank()) +
  theme(legend.title = element_text(size = 8)) +
  ylim(0, 150) +
  scale_fill_manual(values = plotcolors, name = "Exposure") +
  scale_x_discrete(breaks = c(0, 1), labels = c("Female", "Male")) +
  ylab("Number exposed")+
  ggtitle("Gender")

dtplot2a <- dtExp2[,.N,keyby=.(over65,exposure)]
p2a <- ggplot(data = dtplot2a, aes(x=factor(over65), y=N)) +
  geom_bar(aes(fill=factor(exposure)), alpha = .8, stat="identity", position = "dodge") +
  ggtheme() +
  theme(axis.title.x = element_blank()) +
  theme(legend.title = element_text(size = 8)) +
  ylim(0, 150) +
  scale_fill_manual(values = plotcolors, name = "Exposure") +
  scale_x_discrete(breaks = c(0, 1), labels = c("65 or younger", "Over 65")) +
  ylab("Number exposed") +
  ggtitle("Age")

grid.arrange(p1a,p2a,nrow=1)

```

## Longitudinal data

To simulate longitudinal data, we start with a 'cross-sectional' data set and convert it to time-dependendent data set. The original cross-sectional data set may or may not include time-dependent data in the columns. In the next example, we measure outcome `Y` once before and twice after intervention `T` in a randomized trial:

```{r, tidy = TRUE}
tdef <- defData(varname = "T", dist="Binary", formula = 0.5)
tdef <- defData(tdef, varname = "Y0", dist = "Normal", formula = 10, variance = 1)
tdef <- defData(tdef, varname = "Y1", dist = "Normal", formula = "Y0 + 5 + 5 * T", variance = 1)
tdef <- defData(tdef, varname = "Y2", dist = "Normal", formula = "Y0 + 10 + 5 * T", variance = 1)

dtTrial <- genData(tdef, 500)
dtTrial
```

The data in longitudinal form is created with a call to **`addPeriods`**. If the cross-sectional data includes time dependent data, then the number of periods `nPeriods` must be the same as the number of time dependent columns. If a variable is not declared as one of the `timevars`, it will be repeated each time period. In this example, the treatment indicator `T` is not specified as a time dependent variable. (Note: if there are two time-dependent variables, it is best to create two data sets and merge them. This will be shown later in the vignette).

```{r, tidy = TRUE}
dtTime <- addPeriods(dtTrial, nPeriods = 3, idvars = "id", timevars = c("Y0", "Y1", "Y2"), timevarName = "Y")
dtTime
```

This is what the longitudinal data look like:

```{r, tidy = TRUE, echo = FALSE, fig.width = 6, fig.height = 3}

avg <- dtTime[,.(Y=mean(Y)), keyby = .(T, period)]

ggplot(data = dtTime, aes(x = factor(period), y = Y)) +
  geom_jitter(aes(color=factor(T)), size = .5, alpha = .8, width = .25) +
  geom_line(data=avg, aes(x = factor(period), y = Y, group = T, color= factor(T)), size=1) +
  xlab("Period") +
  scale_color_manual(values = plotcolors[c(3,1)], 
                     labels = c("Ctrl", "Trt")) +
  theme(legend.title=element_blank()) +
  ggtheme("grey90") +
  theme(legend.key=element_rect(fill=NA))
```

## Clustered data

The function `genCluster` generates multilevel or clustered data based on a previously generated data set that is one "level" up from the clustered data. For example, if there is a data set that contains school level (considered here to be level 2), classrooms (level 1) can be generated. And then, students (now level 1) can be generated within classrooms (now level 2)

In the example here, we do in fact generate school, classe, and student level data. There are eight schools, four of which are randomized to receive an intervention. The number of classes per school varies, as does the number of students per class. (It is straightforward to generate fully balanced data by using constant values.) The outcome of interest is a test score, which is influenced by gender and the intervention. In addition, test scores vary by schools, and by classrooms, so the simulation provides *random effects* at each of these levels.

We start by definining the school level data:

```{r, tidy = TRUE}
gen.school <- defData(varname="s0", dist = "Normal", 
                      formula = 0, variance = 3, id = "idSchool"
)
gen.school <- defData(gen.school, varname = "nClasses", 
                      dist = "NoZeroPoisson", formula = 3
)

dtSchool <- genData(gen.school, 8)
dtSchool <- trtAssign(dtSchool, n = 2)

dtSchool

```

The classroom level data are generated with a call to `genCluster`, and then school level data is added by a call to `addColumns`:

```{r, tidy = TRUE}
gen.class <- defData(varname = "c0", dist = "Normal", formula = 0, 
                     variance = 2)
gen.class <- defData(gen.class, varname = "nStudents", dist = "NoZeroPoisson", formula = 20
)

dtClass <- genCluster(dtSchool, "idSchool", numIndsVar = "nClasses",level1ID = "idClass")
dtClass <- addColumns(gen.class, dtClass)

head(dtClass, 10)
```

Finally, the student level data are added using the same process:

```{r, tidy = TRUE}
gen.student <- defData(varname="Male", dist="Binary", formula=0.5)
gen.student <- defData(gen.student, varname="age", dist = "Uniform", formula="9.5, 10.5")
gen.student <- defData(gen.student, varname="test", dist = "Normal",
                       formula = "50 - 5*Male + s0 + c0 + 8 * (trtGrp==2)",                           variance = 2)
dtStudent <- genCluster(dtClass,cLevelVar="idClass", numIndsVar = "nStudents",                        level1ID = "idChild")

dtStudent <- addColumns(gen.student, dtStudent)
```

This is what the clustered data look like. Each classroom is represented by a box, and each school is representing by a color. The intervention group is highlighted by dark outlines:

```{r, tidy = TRUE, echo = FALSE, fig.width = 7, fig.height = 3}
ggplot(data=dtStudent,aes(x=factor(idClass),y=test,group=idClass)) +
  geom_boxplot(aes(color=factor(trtGrp), fill = factor(idSchool)))+
  xlab("Classes")+
  ylab("Test scores") +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  scale_fill_manual(values = cbbPalette, guide = FALSE) +
  scale_color_manual(values = c("grey80", "#000000"),
                    labels = c("Ctrl", "Rx"),
                    guide = guide_legend(title = NULL,
                                         override.aes = list(shape = 1,
                                                             keywidth=8
                                                             )
                                         )
                    ) +
  theme(legend.key=element_rect(fill=NA)) +
  ggtheme()
```

## Missing data

After generating a complete data set, it is possible to generate missing data. `defMiss` defines the parameters of missingness. `genMiss` generates a missing data matrix of indicators for each field. Indicators are set to 1 if the data are missing for a subject, 0 otherwise. `genObs` creates a data set that reflects what would have been observed had data been missing; this is a replicate of the orginal data set with "NAs" replacing values where missing data has been generated.

By controlling the parameters of missingness, it is possible to represnt different missing data mechanisms: (1) *missing completely at random* (MCAR), where the probability missing data is independent of any covariates, measured or unmeasured, that are associated with the measrue (2) *missing at random* (MAR), where the probability of subject missing data is a function only of observed covariates that are associated with the measure, and (3) *not missing at random* (NMAR), where the probability of missing data is related to unmeasured covariates that are associated with measure.

These possibilities are illustrated with an example. A data set of 1000 observations with three "outcome" measures" `x1`, `x2`, and `x3` is defined. This data set also includes two independent predictors, `m` and `u` that largely determine the value of each outcome (subject to random noise).

```{r, tidy = TRUE}
def1 <- defData(varname = "m", dist = "Binary", formula = .5)
def1 <- defData(def1, "u", dist = "Binary", formula = .5)
def1 <- defData(def1, "x1", dist="Normal", formula = "20*m + 20*u", variance = 2)
def1 <- defData(def1, "x2", dist="Normal", formula = "20*m + 20*u", variance = 2)
def1 <- defData(def1, "x3", dist="Normal", formula = "20*m + 20*u", variance = 2)

dtAct <- genData(def1, 1000)
```

In this example, the missing data mechanism is different for each outcome. Missingness for `x1` is MCAR, since the probability of missing is fixed. Missingness for `x2` is MAR, since missingness is a function of `m`, a measured predictor of `x2`. And missingness for `x3` is NMAR, since the probability of missing is dependent on `u`, an unmeasured predictor of `x3`:

```{r, tidy = TRUE}
defM <- defMiss(varname = "x1", formula = .15, logit.link = FALSE)
defM <- defMiss(defM, varname = "x2", formula = ".05 + m * 0.25", logit.link = FALSE)
defM <- defMiss(defM, varname = "x3", formula = ".05 + u * 0.25", logit.link = FALSE)
defM <- defMiss(defM, varname = "u", formula = 1, logit.link = FALSE) # not observed

missMat <- genMiss(dtAct, defM, idvars = "id")
dtObs <- genObs(dtAct, missMat, idvars = "id")
```

```{r, tidy = TRUE}
missMat
dtObs
```

The impacts of the various data mechanisms on estimation can be seen with a simple calculation of means using both the "true" data set without missing data as a comparison for the "observed" data set. Since `x1` is MCAR, the averages for both data sets are roughly equivalent. However, we can see below that estimates for `x2` and `x3` are biased, as the difference between observed and actual is not close to 0:

```{r tidy=TRUE}
# Two functions to calculate means and compare them

rmean <- function(var, digits = 1) {
  round(mean(var, na.rm=TRUE), digits)
}

showDif <- function(dt1, dt2, rowName = c("Actual", "Observed", "Difference")) {
  dt <- data.frame(rbind(dt1, dt2, dt1 - dt2))
  rownames(dt) <- rowName
  return(dt)
}

# data.table functionality to estimate means for each data set

meanAct <- dtAct[,.(x1 = rmean(x1), x2 = rmean(x2), x3 = rmean(x3))]
meanObs <- dtObs[,.(x1 = rmean(x1), x2 = rmean(x2), x3 = rmean(x3))]

showDif(meanAct, meanObs)
```

After adjusting for the measured covariate `m`, the bias for the estimate of the mean of `x2` is mitigated, but not for `x3`, since `u` is not observed:

```{r tidy=TRUE}
meanActm <- dtAct[,.(x1 = rmean(x1), x2 = rmean(x2), x3 = rmean(x3)), keyby = m]
meanObsm <- dtObs[,.(x1 = rmean(x1), x2 = rmean(x2), x3 = rmean(x3)), keyby = m]
```
```{r, tidy = TRUE}
# compare observed and actual when m = 0

showDif(meanActm[m==0, .(x1, x2, x3)], meanObsm[m==0, .(x1, x2, x3)])

# compare observed and actual when m = 1

showDif(meanActm[m==1, .(x1, x2, x3)], meanObsm[m==1, .(x1, x2, x3)])
```


## Longitudinal data with missingness

Missingness can occur, of course, in the context of longitudinal data. `missDef` provides two additional arguments that are relevant for these types of datas: `baseline` and `monotonic`. In the case of variables that are measured at baseline only, a missing value would be reflected throughout the course of the study. In the case where a variable is time-dependent (i.e it is measured at each time point), it is possible to declare missingness to be  *monotonic*. This means that if a value for this field is missing at time `t`, then values will also be missing at all times `T > t` as well. The call to `genMiss` must set `repeated` to TRUE.

The following two examples an outcome variable `y` that is measured over time, whose value is a function of time and an observed exposure: 

```{r, tidy = TRUE}

# use baseline definitions from previous example

dtAct <- genData(def1, 120)
dtAct <- trtObserve(dtAct, formulas = .5, logit.link = FALSE, grpName = "rx")

# add longitudinal data

defLong <- defData(varname = "y", dist = "Normal", formula = "10 + period*2 + 2 * rx", variance = 2)

dtTime <- addPeriods(dtAct, nPeriods = 4)
dtTime <- addColumns(defLong, dtTime)
```

In the first case, missingness is not monotonic; a subject might miss a measurement but returns for subsequent measurements:

```{r, tidy = TRUE}

# missingness for y is not monotonic

defMlong <- defMiss(varname = "x1", formula = .20, baseline = TRUE)
defMlong <- defMiss(defMlong,varname = "y", formula = "-1.5 - 1.5 * rx + .25*period", logit.link = TRUE, baseline = FALSE, monotonic = FALSE)

missMatLong <- genMiss(dtTime, defMlong, idvars = c("id","rx"), repeated = TRUE, periodvar = "period")
```

Here is a conceptual plot that shows the pattern of missingness. Each row represents an indiviudal, and each box represents a time period. A box that is colored reflects missing data; a box colored grey reflects observed. The missingness pattern is show for two variables `x1` and `y`:

```{r tidy=TRUE, echo=FALSE, fig.width = 7, fig.height = 6}
xp10 <- ggmissing(missMatLong, varSelect="rx", varLevel = 0, idvar = "id",
                 periodvar = "period", missvar="x1", pcolor="#1C5974",
                 title = "x1: baseline (control)")

xp11 <- ggmissing(missMatLong, varSelect="rx", varLevel = 1, idvar = "id",
                 periodvar = "period", missvar="x1", pcolor="#B84226",
                 title = "x1: baseline (exposed)")

xp20 <- ggmissing(missMatLong, varSelect="rx", varLevel = 0, idvar = "id",
                 periodvar = "period", missvar="y", pcolor="#1C5974",
                 title = "y: not monotonic (control)")

xp21 <- ggmissing(missMatLong, varSelect="rx", varLevel = 1, idvar = "id",
                 periodvar = "period", missvar="y", pcolor="#B84226",
                 title = "y: not monotonic (exposed)")

grid.arrange(xp10, xp20, xp11, xp21,
             nrow = 2,
             bottom = textGrob("Periods", gp = gpar(cex=.8)) #,
#             left = textGrob("ID", gp = gpar(cex = .8), rot = 90)
)


```

In the second case, missingness is montonic; once a subject misses a measurement for `y`, there are no subsequent measurements:

```{r tidy=TRUE}
# missingness for y is not monotonic

defMlong <- defMiss(varname = "x1", formula = .20, baseline = TRUE)
defMlong <- defMiss(defMlong,varname = "y", formula = "-1.8 - 1.5 * rx + .25*period", logit.link = TRUE, baseline = FALSE, monotonic = TRUE)

missMatLong <- genMiss(dtTime, defMlong, idvars = c("id","rx"), repeated = TRUE, periodvar = "period")
```

```{r tidy=TRUE, echo=FALSE, fig.width = 7, fig.height = 6}
xp10 <- ggmissing(missMatLong, varSelect="rx", varLevel = 0, idvar = "id",
                 periodvar = "period", missvar="x1", pcolor="#1C5974",
                 title = "x1: baseline (control)")

xp11 <- ggmissing(missMatLong, varSelect="rx", varLevel = 1, idvar = "id",
                 periodvar = "period", missvar="x1", pcolor="#B84226",
                 title = "x1: baseline (exposed)")

xp20 <- ggmissing(missMatLong, varSelect="rx", varLevel = 0, idvar = "id",
                 periodvar = "period", missvar="y", pcolor="#1C5974",
                 title = "y: monotonic (control)")

xp21 <- ggmissing(missMatLong, varSelect="rx", varLevel = 1, idvar = "id",
                 periodvar = "period", missvar="y", pcolor="#B84226",
                 title = "y: monotonic (exposed)")

grid.arrange(xp10, xp20, xp11, xp21,
             nrow = 2,
             bottom = textGrob("Periods", gp = gpar(cex=.8)) #,
#             left = textGrob("ID", gp = gpar(cex = .8), rot = 90)
)


```

## Other topics

* Merge data
* Correlated data
